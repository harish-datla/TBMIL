{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8916864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "import math\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "def compute_log_probability(sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "        log_likelihood = -outputs.loss.item() * inputs[\"input_ids\"].size(1)\n",
    "    return log_likelihood\n",
    "\n",
    "sentences = [\n",
    "    \"the mouse ate the cheese\",\n",
    "    \"the cheese ate the mouse\",\n",
    "    \"mouse the the cheese ate\"\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    logp = compute_log_probability(sentence)\n",
    "    prob = math.exp(logp)\n",
    "    print(f\"Sentence: '{sentence}'\")\n",
    "    print(f\"Log Probability: {logp:.4f}\")\n",
    "    print(f\"Probability: {prob:.2e}\")\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
